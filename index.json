[{"authors":["admin"],"categories":null,"content":"Since November 2017, I am a PhD student in Smart Computing. I received my Bachelor’s Degree in Computer Science (Ingegneria Informatica) at University of Florence. In April 2017, I obtained the Master’s Degree with honors in Computer and Automation Engineering at University of Siena defending the thesis called “Information Extraction by Learning Deep Architectures from Constraints”.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/andrea-zugarini/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/andrea-zugarini/","section":"authors","summary":"Since November 2017, I am a PhD student in Smart Computing. I received my Bachelor’s Degree in Computer Science (Ingegneria Informatica) at University of Florence. In April 2017, I obtained the Master’s Degree with honors in Computer and Automation Engineering at University of Siena defending the thesis called “Information Extraction by Learning Deep Architectures from Constraints”.","tags":null,"title":"Andrea Zugarini","type":"authors"},{"authors":[],"categories":[],"content":"The main goal of the project is the analysis of the diachronic evolution and variance of the vulgar Italian language. In order to do so, we retrieved an heterogeneous literary text corpus from Biblioteca Italiana, a digital library project collecting the most significant texts of the Italian literature, ranging from the Middle Age to the 20th century. The analyzed corpus contains poetry, prose, epistles and correspondence by the most important Italian authors ranging from the dawn of the vulgar language to the Reinassance Age.\n","date":1602421929,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602421929,"objectID":"e7afaba07bc26f7f5bbf3ec579d0e39d","permalink":"/project/vulgaris/","publishdate":"2020-10-11T15:12:09+02:00","relpermalink":"/project/vulgaris/","section":"project","summary":"Analysis of the diachronic evolution and variance of the vulgar italian language","tags":["vardial2020","language modeling","perplexity-based methods","corpus","language varieties"],"title":"Vulgaris","type":"project"},{"authors":[],"categories":["natural language generation","Poem generation"],"content":"We study the problem of neural poem generation, focussing on Dante Alighieri, widely known for his Divine Comedy. This challenging task, where the machine has to capture the linguistic features that characterize the poet from the few available author\u0026rsquo;s works, it is addressed by using a syllable-based neural language model trained with a multi-stage procedure that exploits non-poetic works of the same author and also other publicly available huge modern Italian corpora.\n","date":1600719738,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600719738,"objectID":"4f138961f403315ed45f7a286dffbb71","permalink":"/project/neural-poem-generation/","publishdate":"2020-09-21T22:22:18+02:00","relpermalink":"/project/neural-poem-generation/","section":"project","summary":"Generation of tercets with the style of the Italian poet Dante Alighieri","tags":["natural language generation","poem generation","syllable representations","language modeling","transfer learning"],"title":"Neural Poetry","type":"project"},{"authors":[],"categories":["epidemiological models"],"content":"The COVID-19 outbreak has stimulated the interest in the proposal of novel epidemiological models to predict the course of the epidemic so as to help planning effective control strategies. In particular, in order to properly interpret the available data, it has become clear that one must go beyond most classic epidemiological models and consider models that, like the recently proposed SIDARTHE, offer a richer description of the stages of infection. The problem of learning the parameters of these models is of crucial importance especially when assuming that they are time-variant, which further enriches their effectiveness. This project focuses on developing a general approach for learning time-variant parameters of dynamic compartmental models from epidemic data.\n","date":1600719685,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600719685,"objectID":"641a69eabe8e2ec48ca57e15e8fce8c7","permalink":"/project/learning-epidemiological-models/","publishdate":"2020-09-21T22:21:25+02:00","relpermalink":"/project/learning-epidemiological-models/","section":"project","summary":"Learning of time-variant coefficients of compartmental for COVID-19 forecasting","tags":["covid-19","sidarthe","compartmental models","pytorch"],"title":"Learning Epidemiological Models","type":"project"},{"authors":["Giuseppe Marra","Andrea Zugarini","Stefano Melacci","Marco Maggini"],"categories":[],"content":"","date":1600630061,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600630061,"objectID":"651f0282f1581f3c6bf94f18955ecdbb","permalink":"/publication/marra-2018-unsupervised/","publishdate":"2020-09-20T21:27:41+02:00","relpermalink":"/publication/marra-2018-unsupervised/","section":"publication","summary":"We consider a scenario where an artificial agent is reading a stream of text composed of a set of narrations, and it is informed about the identity of some of the individuals that are mentioned in the text portion that is currently being read. The agent is expected to learn to follow the narrations, thus disambiguating mentions and discovering new individuals. We focus on the case in which individuals are entities and relations and propose an end-to-end trainable memory network that learns to discover and disambiguate them in an online manner, performing one-shot learning and dealing with a small number of sparse supervisions. Our system builds a not-given-in-advance knowledge base, and it improves its skills while reading the unsupervised text. The model deals with abrupt changes in the narration, considering their effects when resolving coreferences. We showcase the strong disambiguation and discovery skills of our model on a corpus of Wikipedia documents and on a newly introduced data set that we make publicly available.","tags":[],"title":"An Unsupervised Character-Aware Neural Approach to Word and Context Representation Learning","type":"publication"},{"authors":["Andrea Zugarini","Jérémy Morvan","Stefano Melacci","Stefan Knerr and Marco Gori"],"categories":[],"content":"","date":1600629857,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600629857,"objectID":"c83784a16f164394ab1c7534ad043c9b","permalink":"/publication/zugarini-2018-combining/","publishdate":"2020-09-20T21:24:17+02:00","relpermalink":"/publication/zugarini-2018-combining/","section":"publication","summary":"This paper faces the problem of extracting knowledge from raw text. We present a deep architecture in the framework of Learning from Constraints that is trained to identify mentions to entities and relations belonging to a given ontology. Each input word is encoded into two latent representations with different coverage of the local context, that are exploited to predict the type of entity and of relation to which the word belongs. Our model combines an entropy-based regularizer and a set of First-Order Logic formulas that bridge the predictions on entity and relation types accordingly to the ontology structure. As a result, the system generates symbolic descriptions of the raw text that are interpretable and well-suited to attach human-level knowledge. We evaluate the model on a dataset composed of sentences about simple facts, that we make publicly available. The proposed system can efficiently learn to discover mentions with very few human supervisions and that the relation to knowledge in the form of logic constraints improves the quality of the system predictions.","tags":[],"title":"Combining deep learning and symbolic processing for extracting knowledge from raw text","type":"publication"},{"authors":["Marco Maggini","Giuseppe Marra","Stefano Melacci","Andrea Zugarini"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600626553,"objectID":"6dd510f755cd4399a1e368d47168f4c4","permalink":"/publication/maggini-2019-learning/","publishdate":"2020-09-20T18:29:12.339924Z","relpermalink":"/publication/maggini-2019-learning/","section":"publication","summary":"We consider a scenario where an artificial agent is reading a stream of text composed of a set of narrations, and it is informed about the identity of some of the individuals that are mentioned in the text portion that is currently being read. The agent is expected to learn to follow the narrations, thus disambiguating mentions and discovering new individuals. We focus on the case in which individuals are entities and relations and propose an end-to-end trainable memory network that learns to discover and disambiguate them in an online manner, performing one-shot learning and dealing with a small number of sparse supervisions. Our system builds a not-given-in-advance knowledge base, and it improves its skills while reading the unsupervised text. The model deals with abrupt changes in the narration, considering their effects when resolving coreferences. We showcase the strong disambiguation and discovery skills of our model on a corpus of Wikipedia documents and on a newly introduced data set that we make publicly available.","tags":["Knowledge Base Construction","Online Learning","Information Extraction"],"title":"Learning in Text Streams: Discovery and Disambiguation of Entity and Relation Instances","type":"publication"},{"authors":["Achille Globo","Antonio Trevisi","Andrea Zugarini","Leonardo Rigutini","Marco Maggini","Stefano Melacci"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600626554,"objectID":"5657bbd059f2c6edde26e1e72753fd90","permalink":"/publication/globo-2019-neural/","publishdate":"2020-09-20T18:29:13.869811Z","relpermalink":"/publication/globo-2019-neural/","section":"publication","summary":"Paraphrasing is the task of re-writing an input text using other words, without altering the meaning of the original content. Conversational systems can exploit automatic paraphrasing to make the conversation more natural, e.g., talking about a certain topic using different paraphrases in different time instants. Recently, the task of automatically generating paraphrases has been approached in the context of Natural Language Generation (NLG). While many existing systems simply consist in rule-based models, the recent success of the Deep Neural Networks in several NLG tasks naturally suggests the possibility of exploiting such networks for generating paraphrases. However, the main obstacle toward neural-network-based paraphrasing is the lack of large datasets with aligned pairs of sentences and paraphrases, that are needed to efficiently train the neural models. In this paper we present a method for the automatic generation of large aligned corpora, that is based on the assumption that news and blog websites talk about the same events using different narrative styles. We propose a similarity search procedure with linguistic constraints that, given a reference sentence, is able to locate the most similar candidate paraphrases out from millions of indexed sentences. The data generation process is evaluated in the case of the Italian language, performing experiments using pointer-based deep neural architectures.","tags":[],"title":"Neural Paraphrasing by Automatically Crawled and Aligned Sentence Pairs","type":"publication"},{"authors":["Andrea Zugarini","Stefano Melacci","Marco Maggini"],"categories":["Poem Generation","Language Modeling"],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600626555,"objectID":"b9208f015899a14996875c64886ccfa2","permalink":"/publication/zugarini-2019-neural/","publishdate":"2020-09-20T18:29:15.037988Z","relpermalink":"/publication/zugarini-2019-neural/","section":"publication","summary":"Motivated by the recent progresses on machine learning-based models that learn artistic styles, in this paper we focus on the problem of poem generation. This is a challenging task in which the machine has to capture the linguistic features that strongly characterize a certain poet, as well as the semantics of the poet’s production, that are influenced by his personal experiences and by his literary background. Since poetry is constructed using syllables, that regulate the form and structure of poems, we propose a syllable-based neural language model, and we describe a poem generation mechanism that is designed around the poet style, automatically selecting the most representative generations. The poetic work of a target author is usually not enough to successfully train modern deep neural networks, so we propose a multi-stage procedure that exploits non-poetic works of the same author, and also other publicly available huge corpora to learn syntax and grammar of the target language. We focus on the Italian poet Dante Alighieri, widely famous for his Divine Comedy. A quantitative and qualitative experimental analysis of the generated tercets is reported, where we included expert judges with strong background in humanistic studies. The generated tercets are frequently considered to be real by a generic population of judges, with relative difference of 56.25% with respect to the ones really authored by Dante, and expert judges perceived Dante’s style and rhymes in the generated text.","tags":["Natural Language Generation","Poem Generation","Language Modeling","Syllable-based Language Models"],"title":"Neural Poetry: Learning to Generate Poems Using Syllables","type":"publication"},{"authors":["Ottavia Spiga","Vittoria Cicaloni","Andrea Zatkova","Lia Millucci","Giulia Bernardini","Andrea Bernini","Barbara Marzocchi","Monica Bianchini","Andrea Zugarini","Alberto Rossi"," others"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600626556,"objectID":"c587fe0cd2c1daef920a434642e12a4c","permalink":"/publication/spiga-2018-new/","publishdate":"2020-09-20T18:29:15.817685Z","relpermalink":"/publication/spiga-2018-new/","section":"publication","summary":"","tags":[],"title":"A new integrated and interactive tool applicable to inborn errors of metabolism: Application to alkaptonuria","type":"publication"},{"authors":["Francesco Giannini","Vincenzo Laveglia","Alessandro Rossi","Dario Zanca","Andrea Zugarini"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600626558,"objectID":"aedfa11b25e976463660e6be1b7b3d52","permalink":"/publication/giannini-2017-neural/","publishdate":"2020-09-20T18:29:16.963121Z","relpermalink":"/publication/giannini-2017-neural/","section":"publication","summary":"This report provides an introduction to some Machine Learning tools within the most common development environments. It mainly focuses on practical problems, skipping any theoretical introduction. It is oriented to both students trying to approach Machine Learning and experts looking for new frameworks.","tags":[],"title":"Neural networks for beginners. A fast implementation in matlab, torch, tensorflow","type":"publication"}]